{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import our dependencies\nimport tensorflow as tf\nimport pandas as pd\nimport tensorflow_hub as hub\nimport os\nimport re\nfrom keras import backend as K\nimport keras.layers as layers\nfrom keras.models import Model, load_model\nfrom keras.engine import Layer\nimport numpy as np\n\n# Initialize session\nsess = tf.Session()\nK.set_session(sess)","execution_count":1,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\nUsing TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\n### Read-in the emails and print some basic statistics\n\nNsamp = 5000\nmax_cells = 50\nmaxlen = 20\n\n# Install Simon\n#!pip install git+https://github.com/algorine/simon\n#from Simon.LengthStandardizer import DataLengthStandardizerRaw\n\n# Enron\nEnronEmails = pd.read_csv('../input/enron-email-bodies/enron_emails_body.csv',dtype='str', header=0)\nprint(\"The size of the Enron emails dataframe is:\")\nprint(EnronEmails.shape)\nprint(\"Ten Enron emails are:\")\nprint(EnronEmails.loc[:10])\n\n# Spam\nSpamEmails = pd.read_csv('../input/fraudulent-email-bodies/fraudulent_emails_body.csv',encoding=\"ISO-8859-1\",dtype='str', header=0)\nprint(\"The size of the Spam emails dataframe is:\")\nprint(SpamEmails.shape)\nprint(\"Ten Spam emails are:\")\nprint(SpamEmails.loc[:10])\n\n# Convert everything to lower-case, put one sentence per column in a tabular\n# structure, truncate to max_cells...\nProcessedEnronEmails=[row.lower().split('\\n')[:max_cells] for row in EnronEmails.iloc[:,1]]\n#print(\"3 Enron emails after Processing (in list form) are:\")\n#print((ProcessedEnronEmails[:3]))\nEnronEmails = pd.DataFrame(random.sample(ProcessedEnronEmails,Nsamp)).transpose()\n\n\n#EnronEmails = DataLengthStandardizerRaw(EnronEmails,max_cells)\n\n\n#print(\"Ten Enron emails after Processing (in DataFrame form) are:\")\n#print((EnronEmails[:10]))\nprint(\"Enron email dataframe after Processing shape:\")\nprint(EnronEmails.shape)\n\nProcessedSpamEmails=[row.lower().split('/n')[:max_cells] for row in SpamEmails.iloc[:,1]]\n#print(\"3 Spam emails after Processing (in list form) are:\")\n#print((ProcessedSpamEmails[:3]))\nSpamEmails = pd.DataFrame(random.sample(ProcessedSpamEmails,Nsamp)).transpose()\n\n\n#SpamEmails = DataLengthStandardizerRaw(SpamEmails,max_cells)\n\n\n#print(\"Ten Spam emails after Processing (in DataFrame form) are:\")\n#print((SpamEmails[:10]))\nprint(\"Spam email dataframe after Processing shape:\")\nprint(SpamEmails.shape)","execution_count":2,"outputs":[{"output_type":"stream","text":"The size of the Enron emails dataframe is:\n(20000, 2)\nTen Enron emails are:\n   Unnamed: 0                                                  0\n0           0                          here is our forecast\\n\\n \n1           1  traveling to have a business meeting takes the...\n2           2                     test successful.  way to go!!!\n3           3  randy,\\n\\n can you send me a schedule of the s...\n4           4                let's shoot for tuesday at 11:45.  \n5           5  greg,\\n\\n how about either next tuesday or thu...\n6           6  please cc the following distribution list with...\n7           7                   any morning between 10 and 11:30\n8           8  1. login:  pallen pw: ke9davis\\n\\n i don't thi...\n9           9  ---------------------- forwarded by phillip k ...\n10         10  mr. buckner,\\n\\n for delivered gas behind san ...\nThe size of the Spam emails dataframe is:\n(5187, 2)\nTen Spam emails are:\n   Unnamed: 0                                               text\n0           1  /nURGENT BUSINESS ASSISTANCE AND PARTNERSHIP./...\n1           2  /nDear Friend,/n/nI am Mr. Ben Suleman a custo...\n2           3  /nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...\n3           4  /nFROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF ...\n4           5  /nDear sir, /n /nIt is with a heart full of ho...\n5           6  PRESIDENT/MANAGING DIRECTOR /n   /nDear Sir/Ma...\n6           7  previous military regimes in our country, gove...\n7           8  1.  70% for us (the officials) /n2.  20% for t...\n8           9  /nDear Sir,/n/nI am Barrister Tunde Dosumu (SA...\n9          10  /nI ascetained your contact through a reliable...\n10         11  /nCHALLENGE SECURITIES LTD./nLAGOS, NIGERIA/n/...\nEnron email dataframe after Processing shape:\n(50, 5000)\nSpam email dataframe after Processing shape:\n(50, 5000)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nraw_data = np.column_stack((SpamEmails,EnronEmails)).T\nprint(\"DEBUG::raw_data:\")\nprint(raw_data.shape)\n\n# corresponding labels\nCategories = ['spam','notspam']\nheader = ([0]*Nsamp)\nheader.extend(([1]*Nsamp))","execution_count":3,"outputs":[{"output_type":"stream","text":"DEBUG::raw_data:\n(10000, 50)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n# function for processing data into the right format\ndef load_data(raw_data,header):\n    indices, labels = [], []\n    for i in range(raw_data.shape[0]):\n        out=''\n        for text in raw_data[i,:]:\n            out = str(text)[:maxlen]+out\n        out = ' '.join(out.split()[0:150])\n        indices.append(out)\n        labels.append(header[i])\n        #print(i)\n    indices = np.array(indices, dtype=object)[:, np.newaxis]\n    items = list(zip(indices, labels))\n    np.random.shuffle(items)\n    indices, labels = zip(*items)\n    indices = np.array(indices)\n    return indices, np.array(labels)\n\n\n# shuffle raw data first\ndef unison_shuffled_copies(a, b):\n    p = np.random.permutation(len(b))\n    data = a[p,:]\n    header = np.asarray(b)[p]\n    return data, list(header)\n\nraw_data, header = unison_shuffled_copies(raw_data, header)\n\n\nidx = int(0.9*raw_data.shape[0])\ntrain_x, train_y = load_data(raw_data[:idx,:],header[:idx]) # 90% of data for training\ntest_x, test_y = load_data(raw_data[idx:,:],header[idx:]) # remaining 10% for testing\n\nprint(\"train_x/train_y list details, to make sure it is of the right form:\")\nprint(len(train_x))\nprint(train_x)\nprint(train_y[:5])\nprint(train_y.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"train_x/train_y list details, to make sure it is of the right form:\n9000\n[['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNonecover this. which has taken placrunning the collectientire universe of gnon-eol trades. whatbooks in which eol areporting each nightcalculations that muthere has apparentlysubject: risk book pcc: bob shults/hou/eeric bass/hou/ect@ectony harris/hou/ect@gossett/hou/ect@ect,to: david oliver/hou12/13/99 07:45 pmtorrey moorer----------------------------------------']\n [\"NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNonegame tonight at 7, isubject: let's get icc: crook/corp/enron@enrmatthew lenhart/hou/baumbach/hou/ect@ectto: o'neal d winfree 08/09/2000 07:52 am from: bryan hull you know that both o\"]\n [\"NoneNoneNoneNoneNoneNoneNone713.306.2508=20mg=20let me know if you hstakes, and make somto 2 millions dollar down the road. frommake it work, or usentinue to work new dth a region or hasn''t want to miss a blcome very familiar weks to come. please anticipation of the on the physical sideed to work extra haill present themselvast approaching and i need to let you guhey guys,=20subject:=20cc:=20 joe; baughman jr., , carrie; reves, brato: seely, michael; sent: mon 11/19/2001from: garcia, miguel-----original messagdaveit was great practic=20how about letting so=20miguel\"]\n ...\n [\"NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNonethe last one. msahave a great (said lboots on. okay, you get repriesubject: re: cc: to: john arnold/hou/from: margaret alleni didn't say you cou\"]\n ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone mrs chrrey mohameed best regards=2cplease reply to thisi want to assure youso my aim of sendingnow =2c that i have and it was my husban and my name was usthis money was realiit is worthy to notedue to some religioumy husband made thimy name is mrs chrre it is my pleadear=2emdrs chrrey mohameed']\n ['NoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNoneNone- http://phpnuke.codmail sent from webma____________________walter gate. have a blessed day.']]\n[1 1 1 1 0]\n(9000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create datasets (Only take up to 150 words for memory)\ntrain_text = train_x\ntrain_label = train_y\n\ntest_text = test_x\ntest_label = test_y","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n\nclass ElmoEmbeddingLayer(Layer):\n    def __init__(self, **kwargs):\n        self.dimensions = 1024\n        self.trainable=True\n        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n                               name=\"{}_module\".format(self.name))\n\n        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n        super(ElmoEmbeddingLayer, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n                      as_dict=True,\n                      signature='default',\n                      )['default']\n        return result\n\n    def compute_mask(self, inputs, mask=None):\n        return K.not_equal(inputs, '--PAD--')\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.dimensions)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to build model\ndef build_model(): \n  input_text = layers.Input(shape=(1,), dtype=\"string\")\n  embedding = ElmoEmbeddingLayer()(input_text)\n  dense = layers.Dense(256, activation='relu')(embedding)\n  pred = layers.Dense(2, activation='softmax')(dense)\n\n  model = Model(inputs=[input_text], outputs=pred)\n\n  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n  model.summary()\n  \n  return model","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build and fit\nmodel = build_model()\nmodel.fit(train_text, \n          train_label,\n          validation_data=(test_text, test_label),\n          epochs=5,\n          batch_size=32)","execution_count":8,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 1)                 0         \n_________________________________________________________________\nelmo_embedding_layer_1 (Elmo (None, 1024)              4         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               262400    \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 514       \n=================================================================\nTotal params: 262,918\nTrainable params: 262,918\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 9000 samples, validate on 1000 samples\nEpoch 1/5\n9000/9000 [==============================] - 141s 16ms/step - loss: 0.3941 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.1541 - val_sparse_categorical_accuracy: 0.9420\nEpoch 2/5\n9000/9000 [==============================] - 131s 15ms/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9256 - val_loss: 0.1787 - val_sparse_categorical_accuracy: 0.9200\nEpoch 3/5\n9000/9000 [==============================] - 131s 15ms/step - loss: 0.2530 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.1160 - val_sparse_categorical_accuracy: 0.9540\nEpoch 4/5\n9000/9000 [==============================] - 130s 14ms/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.1495 - val_sparse_categorical_accuracy: 0.9370\nEpoch 5/5\n9000/9000 [==============================] - 131s 15ms/step - loss: 0.1352 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1310 - val_sparse_categorical_accuracy: 0.9600\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"<keras.callbacks.History at 0x7fbf501dbc88>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('ElmoModel.h5')\n# Accuracy\npreds = model.predict(test_text).argmax(axis=-1)\n#print(test_label)\nprint(np.sum(test_label == preds) / test_label.shape[0])","execution_count":9,"outputs":[{"output_type":"stream","text":"0.96\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}